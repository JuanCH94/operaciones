{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<table style=\"width: 100%;\"> <tr> <td style=\"width: 20%; vertical-align: top;\"> <img src=\"https://upload.wikimedia.org/wikipedia/commons/archive/f/fb/20161010213812%21Escudo-UdeA.svg\" alt=\"UdeA\" height=\"150px\"> </td> <td style=\"width: 80%; padding-left: 20px;\"> <strong style=\"font-size: 30px;\">MODELO DE REDES NEURONALES CONVOLUCIONALES PARA UN SISTEMA DE CLASIFICACIÓN CON IMÁGENES DE RESONANCIA MAGNÉTICA </strong><br><br> <span style=\"font-size: 30px;\"> Luisa Fernanda Alzate Cuartas <br> Juan Camilo Henao Caro<br>Isabella Mendez Hoyos<br> Fernando Antonio Piñeres Ramos </span> </td> </tr> </table>"],"metadata":{"id":"Yo6qGBSdr8l9"}},{"cell_type":"markdown","source":["#### IMPORTE E INSTALACIÓN DE LIBRERÍAS"],"metadata":{"id":"VnlMJuDasgZM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKB8DEFQnL_V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749085593282,"user_tz":300,"elapsed":18677,"user":{"displayName":"LUISA FERNANDA ALZATE CUARTAS","userId":"16318270997305218310"}},"outputId":"82b7f9f0-a586-419e-b68f-f082d91aa54a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Conectar con Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import sys #Interactuar de manera directa con el intérprete de Python\n","import os #Se utiliza para interactuar con el sistema operativo"]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/operaciones' # Configura el entorno para trabajar con archivos en Google Drive\n","sys.path.append(path) # Permite importar módulos desde esta ruta.\n","os.chdir(path) # Cambia el directorio de trabajo actual"],"metadata":{"id":"Pg5Qol-fnynf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instalación de librerías.\n","!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WowX7JLroWCS","executionInfo":{"status":"ok","timestamp":1749085600782,"user_tz":300,"elapsed":4639,"user":{"displayName":"LUISA FERNANDA ALZATE CUARTAS","userId":"16318270997305218310"}},"outputId":"7dc95ae1-bae2-4fab-82a0-64ce2f9a2805"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n","Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"]}]},{"cell_type":"code","source":["# Importe de librerías.\n","import optuna\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.utils import shuffle\n","import joblib"],"metadata":{"id":"VnY1km6Wolbo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### LECTURA DEL CONJUNTO DE IMÁGENES"],"metadata":{"id":"Mis_sxbLwjy_"}},{"cell_type":"code","source":["### cargar bases_procesadas ####\n","x_train = joblib.load('/content/drive/MyDrive/operaciones/salidas/data_final/x_train.pkl')\n","y_train = joblib.load('/content/drive/MyDrive/operaciones/salidas/data_final/y_train.pkl')\n","x_test = joblib.load('/content/drive/MyDrive/operaciones/salidas/data_final/x_test.pkl')\n","y_test = joblib.load('/content/drive/MyDrive/operaciones/salidas/data_final/y_test.pkl')\n","x_val = joblib.load('/content/drive/MyDrive/operaciones/salidas/data_final/x_val.pkl')\n","y_val = joblib.load('/content/drive/MyDrive/operaciones/salidas/data_final/y_val.pkl')"],"metadata":{"id":"A3homCJZpQ79"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ESCALADO DEL CONJUNTO DE DATOS."],"metadata":{"id":"EP5NALsOwyh_"}},{"cell_type":"code","source":["#### Escalar ######################\n","x_train=x_train.astype('float32') ## para poder escalarlo\n","x_test=x_test.astype('float32') ## para poder escalarlo\n","x_val=x_val.astype('float32') ## para poder escalarlo\n","x_train.max()\n","x_train.min()\n","x_test.max()\n","x_test.min()\n","x_val.max()\n","x_val.min()\n","\n","x_train /=255 ### escalarlo para que quede entre 0 y 1, con base en el valor máximo\n","x_test /=255\n","x_val /=255"],"metadata":{"id":"eWzKlwvCp5u9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### verificar tamaños\n","\n","x_train.shape\n","x_test.shape\n","x_val.shape\n","\n","np.prod(x_train[1].shape) ## cantidad de variables por imagen\n","\n","np.unique(y_train, return_counts=True)\n","np.unique(y_test, return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U4_YcjB8rVwJ","executionInfo":{"status":"ok","timestamp":1749085644524,"user_tz":300,"elapsed":19,"user":{"displayName":"LUISA FERNANDA ALZATE CUARTAS","userId":"16318270997305218310"}},"outputId":"7e487d0d-c07d-4f3a-b8d8-3ff0d29181f2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 1, 2, 3]), array([154, 165, 200, 176]))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["#### DATA AUGMENTATION"],"metadata":{"id":"O9h34xEUxDFV"}},{"cell_type":"code","source":["# Crear el generador de augmentación\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    fill_mode='nearest' #se rellena los pixeles vacios con el pixel mas cercano\n",")\n","\n","# Obtener clases y sus tamaños\n","classes, counts = np.unique(y_train, return_counts=True)\n","max_count = max(counts)\n","\n","x_train_aug = []\n","y_train_aug = []\n","\n","# Aumentar solo las clases que tengan menos de max_count\n","for c in classes:\n","    x_class = x_train[y_train == c]\n","    y_class = y_train[y_train == c]\n","    n_samples_needed = max_count - len(x_class)\n","\n","    # Agregar los datos originales\n","    x_train_aug.extend(x_class)\n","    y_train_aug.extend(y_class)\n","\n","    # Generar muestras augmentadas si es necesario\n","    if n_samples_needed > 0:\n","        gen = datagen.flow(x_class, y_class, batch_size=1)\n","        for _ in range(n_samples_needed):\n","            x_aug, y_aug = next(gen)\n","            x_train_aug.append(x_aug[0])\n","            y_train_aug.append(y_aug[0])\n","\n","# Convertir a arrays numpy\n","x_train_balanced = np.array(x_train_aug)\n","y_train_balanced = np.array(y_train_aug)\n","\n","# Barajar (opcional pero recomendable)\n","from sklearn.utils import shuffle\n","x_train_balanced, y_train_balanced = shuffle(x_train_balanced, y_train_balanced, random_state=42)\n","\n","# Guardar si deseas\n","joblib.dump(x_train_balanced, '/content/drive/MyDrive/operaciones/salidas/data_final/x_train_balanced.pkl')\n","joblib.dump(y_train_balanced, '/content/drive/MyDrive/operaciones/salidas/data_final/y_train_balanced.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdZYBZi7tCxP","executionInfo":{"status":"ok","timestamp":1749085665669,"user_tz":300,"elapsed":19034,"user":{"displayName":"LUISA FERNANDA ALZATE CUARTAS","userId":"16318270997305218310"}},"outputId":"5636ae93-4d45-43f8-91c1-b67d982aa401"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/operaciones/salidas/data_final/y_train_balanced.pkl']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["###### verificar tamaños\n","\n","np.unique(x_train_balanced, return_counts=True)\n","np.unique(y_train_balanced, return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqMzxPigubN2","executionInfo":{"status":"ok","timestamp":1749085684994,"user_tz":300,"elapsed":7543,"user":{"displayName":"LUISA FERNANDA ALZATE CUARTAS","userId":"16318270997305218310"}},"outputId":"370f0891-59b9-4ba7-c87d-04ce7ce78012"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 1, 2, 3]), array([1600, 1600, 1600, 1600]))"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["#### MODELO DE REDES NEURONALES CONVOLUSIONALES."],"metadata":{"id":"GkOIjcbCxZGt"}},{"cell_type":"code","source":["# Asegúrate de que los datos estén barajados\n","x_train_balanced, y_train_balanced = shuffle(x_train_balanced, y_train_balanced, random_state=42)\n","\n","# Input shape e info de clases\n","input_shape = x_train_balanced.shape[1:]  # (alto, ancho, canales)\n","num_classes = len(np.unique(y_train_balanced))  # En tu caso, 4\n","\n","# Definir el modelo\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","    BatchNormalization(),\n","    MaxPooling2D(pool_size=(2, 2)),\n","\n","    Conv2D(64, (3, 3), activation='relu'),\n","    BatchNormalization(),\n","    MaxPooling2D(pool_size=(2, 2)),\n","\n","    Conv2D(128, (3, 3), activation='relu'),\n","    BatchNormalization(),\n","    MaxPooling2D(pool_size=(2, 2)),\n","\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","# Compilar el modelo\n","model.compile(\n","    optimizer= 'Adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Callbacks\n","early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n","checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n","\n","# Entrenamiento\n","history = model.fit(\n","    x_train_balanced, y_train_balanced,\n","    #validation_data=(x_val, y_val),\n","    epochs=10,\n","    batch_size=32,\n","    callbacks=[early_stop, checkpoint]\n",")"],"metadata":{"id":"RcS7x3xDlZbq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7809bb96-e895-461d-d1b3-cd02751fc1f2","executionInfo":{"status":"ok","timestamp":1749090965035,"user_tz":300,"elapsed":2294573,"user":{"displayName":"LUISA FERNANDA ALZATE CUARTAS","userId":"16318270997305218310"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 2s/step - accuracy: 0.5414 - loss: 3.0361\n","Epoch 2/10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n","  current = self.get_monitor_value(logs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/model_checkpoint.py:209: UserWarning: Can save best model only with val_loss available, skipping.\n","  self._save_model(epoch=epoch, batch=None, logs=logs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 2s/step - accuracy: 0.6435 - loss: 0.8344\n","Epoch 3/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 3s/step - accuracy: 0.6836 - loss: 0.7382\n","Epoch 4/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 3s/step - accuracy: 0.7033 - loss: 0.6959\n","Epoch 5/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 2s/step - accuracy: 0.7417 - loss: 0.6627\n","Epoch 6/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 3s/step - accuracy: 0.7323 - loss: 0.5990\n","Epoch 7/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 3s/step - accuracy: 0.7661 - loss: 0.5556\n","Epoch 8/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 2s/step - accuracy: 0.7864 - loss: 0.4893\n","Epoch 9/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 2s/step - accuracy: 0.8076 - loss: 0.4499\n","Epoch 10/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 2s/step - accuracy: 0.8123 - loss: 0.4190\n"]}]}]}